{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from dimensional_structure.EFA_plots import get_communality\n",
    "from dimensional_structure.utils import abs_pdist\n",
    "from ontology_mapping.reconstruction_plots import (plot_factor_reconstructions,\n",
    "                                                    plot_reconstruction_hist,\n",
    "                                                  plot_distance_recon,\n",
    "                                                  plot_reconstruction_2D)\n",
    "from ontology_mapping.reconstruction_utils import (combine_files,\n",
    "                                                   load_files,\n",
    "                                                  summarize_k,\n",
    "                                                  summarize_k_partial)\n",
    "from selfregulation.utils.plot_utils import beautify_legend, format_num, save_figure\n",
    "from selfregulation.utils.utils import get_info, get_recent_dataset, get_retest_data\n",
    "from selfregulation.utils.result_utils import load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_recent_dataset()\n",
    "results_dir = get_info('results_directory')\n",
    "ontology_results_dir = path.join(results_dir, 'ontology_reconstruction', dataset, '*', 'oblimin')\n",
    "retest_data = get_retest_data(dataset.replace('Complete', 'Retest'))\n",
    "plot_dir = glob(path.join(ontology_results_dir, 'Plots'))[0]\n",
    "save=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results(dataset)['task']\n",
    "c = results.EFA.get_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR_files = glob(path.join(ontology_results_dir, 'KNNR_*'))\n",
    "KNNR_loaded = load_files(KNNR_files)\n",
    "KNNR_var_summary, KNNR_best_params, KNNR_reconstructions = summarize_k(KNNR_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNRind_files = glob(path.join(ontology_results_dir, 'KNNRind_*'))\n",
    "KNNRind_loaded = load_files(KNNRind_files)\n",
    "KNNRind_var_summary, KNNRind_best_params, KNNRind_reconstructions = summarize_k(KNNRind_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNRpartial_files = glob(path.join(ontology_results_dir, 'KNNRpartial_*'))\n",
    "KNNRpartial_loaded = load_files(KNNRpartial_files)\n",
    "KNNRpartial_var_summary = summarize_k_partial(KNNRpartial_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_files = glob(path.join(ontology_results_dir, '*RidgeCV*'))\n",
    "ridge_loaded = load_files(ridge_files)\n",
    "linear_files = glob(path.join(ontology_results_dir, '*Linear*'))\n",
    "linear_loaded = load_files(linear_files)\n",
    "linear_reconstructions = {'Linear': combine_files(linear_loaded),\n",
    "                         'RidgeCV': combine_files(ridge_loaded)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNR_reconstructions.query('label==\"partial_reconstruct\"') \\\n",
    "    .groupby('pop_size')['corr_score'].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNNRind_reconstructions.query('label==\"partial_reconstruct\"') \\\n",
    "    .groupby('pop_size')['corr_score'].agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame()\n",
    "for clf, df in linear_reconstructions.items():\n",
    "    tmp = df.query('label==\"partial_reconstruct\"') \\\n",
    "        .groupby('pop_size').corr_score.agg([np.mean, np.std])\n",
    "    tmp.loc[:,'clf'] = clf\n",
    "    summary = pd.concat([summary, tmp], sort=False)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More focuses analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructions = {'KNNR': KNNR_reconstructions,\n",
    "                   'RidgeCV': linear_reconstructions['RidgeCV']}\n",
    "reconstructed_vars = sorted(KNNR_reconstructions['var'].unique())\n",
    "assert set(reconstructed_vars) == set(reconstructions['RidgeCV']['var'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well are we reconstructing distances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_loadings = results.EFA.get_loading(c=c).loc[reconstructed_vars]\n",
    "orig_distances = pd.DataFrame(squareform(abs_pdist(orig_loadings)), index=orig_loadings.index, columns=orig_loadings.index)\n",
    "\n",
    "reconstructed_distances = {}\n",
    "for name, reconstruction in reconstructions.items():\n",
    "    pop_sizes = sorted(reconstruction.pop_size.dropna().unique())\n",
    "    for pop_size in pop_sizes:\n",
    "        reconstructed_distances[name+'_%03d' % pop_size] = []\n",
    "        for rep in range(1, int(reconstruction.rep.max()+1)):\n",
    "            reconstructed_loadings = reconstruction.query('pop_size == %s and rep==%s' % (pop_size, rep)).sort_values(by='var')\n",
    "            distances = abs_pdist(reconstructed_loadings.iloc[:,:c])\n",
    "            reconstructed_distances[name+'_%03d' % pop_size].append(distances)\n",
    "            \n",
    "mean_reconstructed_distances = {}\n",
    "std_reconstructed_distances = {}\n",
    "\n",
    "for key, distances in reconstructed_distances.items():\n",
    "    mean_reconstructed_distances[key] = \\\n",
    "            pd.DataFrame(squareform(np.mean(distances, 0)),\n",
    "                                    index=orig_loadings.index, \n",
    "                                    columns=orig_loadings.index)\n",
    "    std_reconstructed_distances[key] = \\\n",
    "            pd.DataFrame(squareform(np.std(distances, 0)),\n",
    "                                    index=orig_loadings.index, \n",
    "                                    columns=orig_loadings.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable characteristics that influence reconstruction quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable characteristics\n",
    "retest_index = [i.replace('.logTr','').replace('.ReflogTr','') for i in reconstructed_vars]\n",
    "retest_vals = retest_data.loc[retest_index,'icc3.k']\n",
    "retest_vals.index = reconstructed_vars\n",
    "communality = get_communality(results.EFA).loc[retest_index]\n",
    "communality.index = reconstructed_vars\n",
    "avg_corr  = abs(results.data.corr()).replace(1,0).mean()\n",
    "avg_corr.name = \"avg_correlation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summaries\n",
    "additional = pd.concat([retest_vals, communality, avg_corr], axis=1, sort=True)\n",
    "reconstruction_summaries = {}\n",
    "for name, reconstruction in reconstructions.items():\n",
    "    s = reconstruction.query('label == \"partial_reconstruct\"') \\\n",
    "        .groupby(['var', 'pop_size']).corr_score.agg(['mean', 'std'])\n",
    "    s = s.reset_index().join(additional, on='var')\n",
    "    reconstruction_summaries[name] = s\n",
    "all_reconstructions = pd.concat(reconstruction_summaries).reset_index()\n",
    "all_reconstructions = all_reconstructions.rename({'level_0': 'approach'}, axis=1).drop('level_1', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does reconstruction success at one population size predict the next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for i,group in all_reconstructions.groupby(['approach', 'pop_size']):\n",
    "    group = group.loc[:,['var','mean']].set_index('var')\n",
    "    group.columns = [i]\n",
    "    tmp.append(group)\n",
    "approach_compare = pd.concat(tmp, axis=1)\n",
    "approach_compare.columns = [i +': '+str(int(j)) for i,j in approach_compare.columns]\n",
    "# correlation of reconstructions\n",
    "corr= approach_compare.corr(method='spearman')\n",
    "overall_correlation = np.mean(corr.values[np.tril_indices_from(corr, -1)])\n",
    "print('DV reconstruction score correlates %s across approaches' % format_num(overall_correlation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model reconstruction success as a function of DV characteristics, approach and subpopulation size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reconstructions.loc[:, 'z_mean'] = np.arctanh(all_reconstructions['mean'])\n",
    "md = smf.mixedlm(\"z_mean ~ (pop_size + Q('icc3.k') + communality)*C(approach, Sum)\", all_reconstructions, groups=all_reconstructions[\"var\"])\n",
    "mdf = md.fit()\n",
    "mdf.summary()\n",
    "\n",
    "# other way to do it\n",
    "# endog, exog = patsy.dmatrices(\"z_mean ~ (pop_size + icc + avg_correlation)*C(approach, Sum)\", all_reconstructions, return_type='dataframe')\n",
    "# md = sm.MixedLM(endog=endog, exog=exog, groups=all_reconstructions['var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Of concern is the average correspondence and variability between the estimated ontological fingerprint of a DV and its \"ground-truth\" (the original estimate when it was part of the EFA model)\n",
    "\n",
    "One way to look at this is just the average reconstruction score (e.g., for example) and variability of reconstruction score as a function of pseudo-pop-size and model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sizes = sorted(reconstructions['KNNR'].pop_size.dropna().unique())\n",
    "colors = sns.color_palette('Set1', n_colors = len(pop_sizes), desat=.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='pop_size', y='mean', hue='approach', data=all_reconstructions, palette='Reds')\n",
    "plt.legend(loc='best')\n",
    "if save:\n",
    "    f.savefig(path.join(plot_dir, 'reconstruction_performance.png'), transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot relationship of performance for each DV over different approach parameterizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = approach_compare.corr(method='spearman')\n",
    "mean_success = approach_compare.mean()\n",
    "plot_df = approach_compare.join(retest_vals).join(communality)\n",
    "size = 2\n",
    "f=sns.pairplot(plot_df.iloc[:,0:8], height=size,\n",
    "             plot_kws={'color': [.4,.4,.4],\n",
    "                       's': plot_df['communality']*250},\n",
    "             diag_kws={'bins': 20,\n",
    "                      'edgecolor': 'k',\n",
    "                      'linewidth': size/4})\n",
    "axes = f.axes\n",
    "# fix axes limits\n",
    "for i in range(len(f.axes)):\n",
    "    for j in range(len(f.axes)):\n",
    "        ax = axes[i][j]\n",
    "        ax.set_ylim([.15,1.1])\n",
    "        ax.tick_params(left=False, bottom=False,\n",
    "                      labelleft=False, labelbottom=False)\n",
    "        if i!=j:\n",
    "            ax.set_xlim([.15,1.1])\n",
    "            ax.plot(ax.get_xlim(), ax.get_ylim(), lw=size, ls=\"--\", c=\".3\", zorder=-1)\n",
    "        if j<i:\n",
    "            x = .6; y = .3\n",
    "            if mean_success[j] > mean_success[i]:\n",
    "                x = .28; y = 1\n",
    "            ax.text(x, y, r'$\\rho$ = %s' % format_num(corr.iloc[i,j]),\n",
    "                   fontsize=size*8)\n",
    "        # change sizing for upper triangle based on icc\n",
    "        if j>i: \n",
    "            ax.set_visible(False)\n",
    "            #ax.collections[0].set_sizes(plot_df['icc']**2*100)\n",
    "            \n",
    "# color diagonal\n",
    "for i,ax in enumerate(f.diag_axes):\n",
    "    ax.set_title(axes[i][0].get_ylabel(), color=colors[i%4], fontsize=size*9)\n",
    "    for patch in ax.patches:\n",
    "        patch.set_facecolor(colors[i%4])\n",
    "        \n",
    "# color labels\n",
    "for i in range(len(f.axes)):\n",
    "    left_ax = axes[i][0]\n",
    "    bottom_ax = axes[-1][i]\n",
    "    left_ax.set_ylabel(left_ax.get_ylabel(), color=colors[i%4],labelpad=10, fontsize=size*9)\n",
    "    bottom_ax.set_xlabel('')\n",
    "    \n",
    "# set tick spacing\n",
    "ax = axes[-1][-2]\n",
    "ax.tick_params(length=1, width=1, labelleft=True, labelbottom=True)\n",
    "ax.set_xticks([.18, 1])\n",
    "ax.set_xticklabels(['0.2', '1.0'], fontsize=size*8, fontweight='bold')\n",
    "ax.set_yticks([1])\n",
    "ax.set_yticklabels(['1.0'], fontsize=size*8, fontweight='bold')\n",
    "# common X\n",
    "f.fig.text(0.5, 0.02, 'Average DV Reconstruction Score', ha='center', fontsize=size*10)\n",
    "if save:\n",
    "    save_figure(f, path.join(plot_dir, 'SFig1_cross_approach_correlations.png'), save_kws={'dpi': 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### K Nearest Visualization (Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Performance by Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desaturated_colors = [sns.desaturate(c, .5) for c in colors]\n",
    "plot_colors = list(zip(colors, desaturated_colors))\n",
    "\n",
    "plot_df = KNNR_var_summary.reset_index()\n",
    "sns.set_context('talk')\n",
    "f, ax = plt.subplots(1, 1, figsize=(12,6))\n",
    "axes = f.get_axes()\n",
    "for i, pop_size in enumerate(pop_sizes):\n",
    "    sns.pointplot(x='k', y='corr_score', hue='weighting', \n",
    "                data=plot_df.query('pop_size==%s' % pop_size),\n",
    "                ax=ax, dodge=.35, alpha=1, join=False, ci=None,\n",
    "                palette = plot_colors[i], label=pop_size)\n",
    "ax.legend().set_visible(False)\n",
    "ax.set_xticklabels([int(i) for i in plot_df.k.unique()])\n",
    "ax.set_ylim(.25,1.1)\n",
    "ax.set_ylabel('Reconstruction Score')\n",
    "plt.subplots_adjust(hspace=.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "#### Performance for each DV\n",
    "\n",
    "Only taking the best parameters from the k-nearest neighbor algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"simon.hddm_drift\"\n",
    "ax = reconstructions['KNNR'].query('var == \"%s\" and pop_size==100' % var).corr_score.hist(bins=30,\n",
    "                                                                          edgecolor='white',\n",
    "                                                                           figsize=[10,6])\n",
    "ax.set_xlabel('Reconstruction Score', fontsize=40, labelpad=30)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(.05))\n",
    "ax.tick_params(labelsize=30)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Histogram of DV reconstruction scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_hist(reconstructions['KNNR'], title='KNNR Reconstruction', size=14)\n",
    "plot_reconstruction_hist(reconstructions['RidgeCV'], title='RidgeCV Reconstruction', size=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "if save:\n",
    "    plot_reconstruction_hist(reconstructions['KNNR'], title='KNNR Reconstruction', size=14,\n",
    "                            filename=path.join(plot_dir, 'Fig3a_KNNR_reconstruction.png'))\n",
    "    plot_reconstruction_hist(reconstructions['RidgeCV'], title='RidgeCV Reconstruction', size=14,\n",
    "                            filename=path.join(plot_dir, 'Fig3b_RidgeCV_reconstruction.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is clearly a bit of variability in the reconstruction accuracy based on the variable itself. While this variability narrows with larger populations, it's still there, and there are a few variables that cannot be reconstructed at all\n",
    "\n",
    "We have access to some characteristics of these DVs (reliability, communality, avg correlation), which we can look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reconstruction score vs. DV characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "ind_vars = ['icc3.k', 'communality'] # 'avg_correlation' could be included\n",
    "N = len(ind_vars)*len(reconstruction_summaries.keys())\n",
    "size=6\n",
    "f, axes = plt.subplots(2,N,figsize=(size*N, size*2))\n",
    "for i, (name, reconstruction) in enumerate(reconstruction_summaries.items()):\n",
    "    for j, var in enumerate(ind_vars):\n",
    "        col_i = len(ind_vars)*i+j\n",
    "        for k, pop_size in enumerate(pop_sizes):\n",
    "            sns.regplot(var, 'mean', \n",
    "                        data=reconstruction.query('pop_size==%s' % pop_size), \n",
    "                        label=pop_size, ax=axes[0][col_i], color=colors[k])\n",
    "            sns.regplot(var, 'std', \n",
    "                        data=reconstruction.query('pop_size==%s' % pop_size), \n",
    "                        label=pop_size, ax=axes[1][col_i], color=colors[k])\n",
    "        # mean plots\n",
    "        axes[0][col_i].tick_params(bottom=False, labelbottom=False)\n",
    "        axes[0][col_i].set_xlabel('')\n",
    "        axes[0][col_i].set_ylabel('')\n",
    "        axes[0][col_i].set_ylim(-.2, 1.1)\n",
    "        # sd plots\n",
    "        axes[1][col_i].set_xlabel(var.title(), fontweight='bold', fontsize=size*4)\n",
    "        axes[1][col_i].set_ylabel('')\n",
    "        axes[1][col_i].set_ylim(-.1, .6)\n",
    "        if col_i==0:\n",
    "            axes[0][col_i].set_ylabel(r'$\\mu$', fontweight='bold', fontsize=size*5)\n",
    "            axes[1][col_i].set_ylabel(r'$\\sigma$', fontweight='bold', fontsize=size*5)\n",
    "        else:\n",
    "            axes[0][col_i].tick_params(left=False, labelleft=False)\n",
    "            axes[1][col_i].tick_params(left=False, labelleft=False)\n",
    "    f.text(0.31+.4*i, .93, name.title(), ha='center', fontsize=size*5)\n",
    "\n",
    "axes[0][-1].legend(title='N')\n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot for paper - just looking at mean for communality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "ind_vars = ['communality'] # 'avg_correlation' could be included\n",
    "N = len(ind_vars)*len(reconstruction_summaries.keys())\n",
    "size=6\n",
    "f, axes = plt.subplots(2,N,figsize=(size*N, size*2))\n",
    "for i, (name, reconstruction) in enumerate(reconstruction_summaries.items()):\n",
    "    for j, var in enumerate(ind_vars):\n",
    "        col_i = len(ind_vars)*i+j\n",
    "        for k, pop_size in enumerate(pop_sizes):\n",
    "            sns.regplot(var, 'mean', ci=None,\n",
    "                        data=reconstruction.query('pop_size==%s' % pop_size), \n",
    "                        label=pop_size, ax=axes[0][col_i], color=colors[k])\n",
    "            sns.regplot(var, 'std', ci=None,\n",
    "                        data=reconstruction.query('pop_size==%s' % pop_size), \n",
    "                        label=pop_size, ax=axes[1][col_i], color=colors[k])\n",
    "        # mean plots\n",
    "        axes[0][col_i].tick_params(bottom=False, labelbottom=False, left=True,\n",
    "                                  length=size/2, width=size/2)\n",
    "        axes[0][col_i].set_xlabel('')\n",
    "        axes[0][col_i].set_ylabel('')\n",
    "        axes[0][col_i].set_ylim(-.2, 1.1)\n",
    "        # sd plots\n",
    "        axes[1][col_i].tick_params(length=size/2, width=size/2, left=True, bottom=True)\n",
    "        axes[1][col_i].set_xlabel(var.title(), fontweight='bold', fontsize=size*4)\n",
    "        axes[1][col_i].set_ylabel('')\n",
    "        axes[1][col_i].set_ylim(-.05, .6)\n",
    "        if col_i==0:\n",
    "            axes[0][col_i].set_ylabel(r'$\\mu$', fontweight='bold', fontsize=size*5)\n",
    "            axes[1][col_i].set_ylabel(r'$\\sigma$', fontweight='bold', fontsize=size*5)\n",
    "        else:\n",
    "            axes[0][col_i].tick_params(left=False, labelleft=False)\n",
    "            axes[1][col_i].tick_params(left=False, labelleft=False)\n",
    "    f.text(0.31+.4*i, .9, name, ha='center', fontsize=size*5)\n",
    "\n",
    "axes[0][-1].legend(title='N', fontsize=size*3)\n",
    "plt.subplots_adjust(wspace=.1, hspace=.1)\n",
    "\n",
    "\n",
    "if save:\n",
    "    save_figure(f, path.join(plot_dir, 'Fig5_DV_characteristics.png'), save_kws={'dpi': 300})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems clear that DVs with poor reliability and communality are not reconstructed well. A less \"analysis based\" way to think about this is reconstruction will be worse if you are far away from the other variables in the set.\n",
    "\n",
    "Similarly, correlation with the overall dataset is important for reconstruction. All of this says that ontological mapping will be more successful if you have an a-priori reason to believe your new variable has something to do with the rest of the variables in the ontology. The weaker you believe that bond, the more data you should collect to articulate the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can dive in and look at one high/mediun/low reliable variable to see the reconstruction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sorted_retest_vals = retest_vals.sort_values().index\n",
    "N = len(sorted_retest_vals)\n",
    "high_var = sorted_retest_vals[N-1]\n",
    "med_var = sorted_retest_vals[N//2]\n",
    "low_var = sorted_retest_vals[0]\n",
    "\n",
    "f, axes = plt.subplots(1,3, figsize=(20,8))\n",
    "for ax, var in zip(axes, [high_var, med_var, low_var]):\n",
    "    retest_in = var.replace('.logTr','').replace('.ReflogTr','')\n",
    "    reliability = format_num(retest_data.loc[retest_in]['icc'])\n",
    "    plot_df = k_reconstruction.query('var == \"%s\" and label==\"partial_reconstruct\"' % var)\n",
    "    sns.boxplot(x='pop_size', y='corr_score', data=plot_df,  ax=ax)\n",
    "    ax.set_title('%s\\nICC: %s' % (var, reliability))\n",
    "    ax.set_ylim([-.2,1.1])\n",
    "plt.subplots_adjust(wspace=.6)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of reconstructed distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distance_recon(mean_reconstructed_distances, orig_distances, size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "if save:\n",
    "    plot_distance_recon(mean_reconstructed_distances, orig_distances, size=15, \n",
    "                       filename=path.join(plot_dir, 'Fig8_distance_reconstructions.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing each factor's reconstruction separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_factor_reconstructions(reconstructions['KNNR'], size=15, plot_diagonal=True, plot_regression=False)\n",
    "plot_factor_reconstructions(reconstructions['RidgeCV'], size=15, plot_diagonal=True, plot_regression=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "if save:\n",
    "    plot_factor_reconstructions(reconstructions['KNNR'], size=10, plot_diagonal=True, plot_regression=False,\n",
    "                                filename=path.join(plot_dir, 'Fig6_KNN_factor_reconstructions.png'))\n",
    "    plot_factor_reconstructions(reconstructions['RidgeCV'], size=10, plot_diagonal=True, plot_regression=False,\n",
    "                                filename=path.join(plot_dir, 'Fig7_RidgeCV_factor_reconstructions.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More complicate, we can visualize this by looking at the MDS plotting:\n",
    "1. The original DVs\n",
    "2. The \"best\" reconstruction using all the data\n",
    "3. The n_reps simulated estimates with a smaller population size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_reconstruction_2D(reconstructions['KNNR'], n_reps=30, n_colored=6, use_background=True, seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Reduced Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.set_style('white')\n",
    "size=12\n",
    "f, axes = plt.subplots(1,2, figsize=(size*2, size*.75))\n",
    "\n",
    "# random subset\n",
    "KNNRpartial_var_summary.pop_size = KNNRpartial_var_summary.pop_size.astype(int)\n",
    "KNNRpartial_var_summary.num_available_measures = KNNRpartial_var_summary.num_available_measures.astype(int)\n",
    "\n",
    "sns.pointplot(x='num_available_measures', y='corr_score', hue='pop_size', data=KNNRpartial_var_summary, \n",
    "             palette=colors, ax=axes[0], ci=None, scale=1.4)\n",
    "leg = axes[0].legend(loc='best', frameon=False, handlelength=0, handletextpad=0,\n",
    "                     fontsize=size*1.5)\n",
    "beautify_legend(leg, colors=colors)\n",
    "leg.get_title().set_fontsize(size*1.5)\n",
    "\n",
    "axes[0].set_ylabel('Reconstruction Score', fontsize=size*3)\n",
    "axes[0].set_xlabel('# of Measures', fontsize=size*2)\n",
    "axes[0].set_title('KNNR with Random Subset', fontsize=size*3)\n",
    "axes[0].tick_params(width=2, length=2, labelsize=size*1.8)\n",
    "\n",
    "# efficiency subset\n",
    "closest_files = glob(path.join(ontology_results_dir, 'KNNRclosest_correlation_summary.pkl'))\n",
    "closest_summary = pd.read_pickle(closest_files[0])\n",
    "sns.pointplot(x='num_available_measures', y='mean', hue='pop_size', data=plot_df, \n",
    "             palette=colors, ci=None, ax=axes[1], scale=1.2)\n",
    "axes[1].get_legend().remove()\n",
    "axes[1].set_ylabel('', fontsize=size*2)\n",
    "axes[1].set_xlabel('# of Measures', fontsize=size*2)\n",
    "axes[1].set_title('KNNR with Efficient Subset', fontsize=size*3)\n",
    "axes[1].tick_params(width=2, length=2, labelsize=size*1.8)\n",
    "\n",
    "# set axes to he the same\n",
    "ylim = (np.min([ax.get_ylim()[0] for ax in axes]), np.max([ax.get_ylim()[1] for ax in axes]))\n",
    "axes[0].set_ylim(ylim)\n",
    "axes[1].set_ylim(ylim)\n",
    "if save:\n",
    "    save_figure(f, path.join(plot_dir, 'Fig4_partial_reconstructions.png'), save_kws={'dpi': 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
