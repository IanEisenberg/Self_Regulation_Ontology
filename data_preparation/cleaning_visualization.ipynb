{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from selfregulation.utils.utils import get_behav_data\n",
    "from selfregulation.utils.plot_utils import format_num\n",
    "from statsmodels.stats.stattools import medcouple\n",
    "\n",
    "from selfregulation.utils.data_preparation_utils import transform_remove_skew, remove_outliers, remove_correlated_task_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_behav_data()\n",
    "selected_variables = get_behav_data()\n",
    "clean = get_behav_data(file = 'meaningful_variables_clean.csv')\n",
    "imputed = get_behav_data(file = 'meaningful_variables_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(cleaned, orig, variables):\n",
    "    outliers = cleaned[variables].isnull() ^ orig[variables].isnull()\n",
    "    return outliers\n",
    "\n",
    "def plot_outliers(cleaned, orig, variables):\n",
    "    outliers = get_outliers(cleaned, orig, variables)\n",
    "    num_with_outliers = np.sum(outliers.mean()>0)\n",
    "    outliers = outliers.loc[:,outliers.mean()>0]\n",
    "    f, axes = plt.subplots(ceil(num_with_outliers/3), 3, figsize=(12,num_with_outliers))\n",
    "    axes = f.get_axes()\n",
    "    i=0\n",
    "    variables=outliers.mean().sort_values().index[::-1]\n",
    "    for name, var in orig[variables].iteritems():\n",
    "        ax = axes[i]\n",
    "        outlier = outliers[name]\n",
    "        var_kept = var[~outlier]\n",
    "        var_outliers = var[outlier]\n",
    "        sns.stripplot(var_kept, ax=ax, size=4, alpha=.5)\n",
    "        sns.stripplot(var_outliers, color='r', ax=ax, size=3)\n",
    "        ax.set_title('\\n'.join(name.split('.')), fontweight='bold')\n",
    "        ax.set_xlabel('')\n",
    "        ax.text(.3, .8, 'Outlier %%: %s' % format_num(outlier.mean()), \n",
    "                transform=ax.transAxes, fontsize=12)\n",
    "        i+=1\n",
    "    plt.subplots_adjust(wspace=.5, hspace=.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure \n",
    "- transform variables that are skewed. \n",
    "- drop variables if they *would still be skewed* after following outliers removal\n",
    "- remove outliers from all variables except the first group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables_clean_transformed = transform_remove_skew(selected_variables)\n",
    "selected_variables_clean = remove_outliers(selected_variables_clean_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare both of these approaches now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All approaches remove skew, obviously. Every kept variable at the end is within our skew thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating skew\n",
    "selected_variables_clean.skew().hist(bins=20, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(df):\n",
    "    df.columns = ['.'.join(i.split('.')[:-1]) if 'logTr' in i else i for i in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "After skewed variables are transformed all variables have outliers removed. The blue distribution here represents the *transformed* distribution. Only variables with at least one outlier are plotted, and they are sorted based on the percent of outliers removed.\n",
    "\n",
    "There is one outlier case which I have dug into after these plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = selected_variables_clean.copy()\n",
    "remove_suffix(tmp)\n",
    "tmp2 = selected_variables_clean_transformed\n",
    "remove_suffix(tmp2)\n",
    "outliers = get_outliers(tmp, tmp2, tmp.columns)\n",
    "# summary\n",
    "tasks_with_outliers = np.sum(outliers.sum()>0)\n",
    "sns.stripplot(outliers.mean()); plt.xlabel('Percent outliers removed', fontsize=20)\n",
    "plt.text(0, .25, \"# Tasks with outliers: %s\" % format_num(tasks_with_outliers),\n",
    "        fontsize=15)\n",
    "plt.title('% Outliers Removed across tasks', fontsize=20)\n",
    "# individual\n",
    "plot_outliers(tmp, tmp2, tmp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One variable seemed odd. It was the shift task model-beta. It seems that a decent number of subjects have a beta value=1 (the starting value). At the same time, the variable is skewed, so it is transformed, making all of those 1's 0's. One option is to remove the extreme outliers before transforming. The variable will no longer be skewed and won't be trasnformed. Instead, I am going to just leave the variable as is, as I don't want to customize the procedure for individual variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(selected_variables.filter(regex='model_beta'), alpha=.5)\n",
    "plt.title('Model Beta before transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(np.log(selected_variables.filter(regex='model_beta')), alpha=.5)\n",
    "plt.title('Model Beta after transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate all distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look clean and imputed data\n",
    "clean = get_behav_data(file = 'meaningful_variables_clean.csv')\n",
    "imputed = get_behav_data(file = 'meaningful_variables_imputed.csv')\n",
    "\n",
    "clean_melted=clean.melt().assign(stage='clean')\n",
    "impute_melted=imputed.melt().assign(stage='imputed')\n",
    "final = pd.concat([clean_melted, impute_melted])\n",
    "# remove missing values\n",
    "final = final.replace([np.inf, -np.inf], np.nan)\n",
    "final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "n_rows=clean.shape[1]\n",
    "f, axes = plt.subplots(n_rows, 2, figsize=(7, n_rows*3))\n",
    "for row, name in enumerate(sorted(final.variable.unique())):\n",
    "    for col, stage in enumerate(['clean','imputed']):\n",
    "        subset = final.query('variable == \"%s\" and stage == \"%s\"' % (name, stage))\n",
    "        if len(subset) > 0:\n",
    "            axes[row][col].hist(subset['value'], bins=20)\n",
    "            axes[row][0].set_ylabel(('\\n').join(name.split('.')), fontsize=15,\n",
    "                                   rotation=0, labelpad=100)\n",
    "            axes[row][col].set_title(str(stage))\n",
    "plt.subplots_adjust(hspace=.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
